---
title: "Segregation and Reproduction"
output: 
  html_notebook:
    toc: true
---

```{r setup, include=FALSE}
# set the working directory always to the project directory (one level up)
knitr::opts_knit$set(root.dir = normalizePath(rprojroot::find_rstudio_root_file())) 
```


## Intro/Overview

This notebook documents the strategy for segregating linked markers from
individuals and forming hybrids.

Here we ensure that we load each of the functions:
```{r}
rfiles <- dir("R", full.names = TRUE)
dump <- lapply(rfiles, source)
```

## Randomize Haplotypes in Founders

We are going to assume no LD (cuz our selected SNPs are quite far apart)
so, to initialize our simulations we are going to need to randomly assign
alleles to one haplotype or another in the founder individuals. 

This is going to work a little like `tablify_nh()` in that we will pass in
a tidy data frame and a list of variants, and then go from there.
So, let's get some data to work on:
```{r get-data}
library(tidyverse)
TT <- readRDS("intermediates/02/test_and_train.rds")
MM <- readRDS("intermediates/02/marker_rankings.rds")
```

So, the function looks like:
```r
`r paste(readLines("R/scramble_founder_haplotypes.R"), collapse = "\n")`
```

Let's see how it works:
```{r demo-scramble}
Test <- TT %>%
  filter(test_or_train == "test")
v1000 <- MM %>%
  filter(selectable == TRUE & cumsum(selectable) <= 1000) %>%
  .$variant

SFG <- scramble_founder_haplotypes(Test, v1000)
```
Now, `SFG` is ready to have some gametes segregated.

## Segregate gametes

In order to maintain maximal sample sizes whilst not incurring the sort of 
inflation of perceived accuracy that comes from sampling with replacement
from the genes in the Test group we are going to segregate two gametes from 
each individual.  These will be the opposites of one another---so, effectively all
of the genetic material in an individual is getting segregated into the two gametes.
(In effect there is no genetic drift in this type of sampling exercise...).  The variance
in what gets segregated around might be a little greater because the two gametes are
not independent, but that is not going to bias the accuracy simulations.  

This function is going to work on a data frame like SFG that has a `hap1` and a `hap2`
column.  It will create new columns `gam1` and `gam2` (gam is short for gamete there).
We just give a chance of recombination between each pair of markers.

Here is what the function looks like

And this is what it looks like when we use it:
```{r use-seg-gam}
SG <- segregate_gametes(H = SFG)
```

## Reproduction

Now all we need is a function that will combine the gametes of randomly chosen individuals 
into new individuals. THis is an interesting problem.  We would like to make use of
all the genetic material that we have from all the test individuals.  We will be
constrained by what types of hybrid categories we are making and the sizes of the
test samples from the different populations.  

### arrange_matings

The way I am going to approach this is to create a function `arrange_matings()` that
returns a data frame that describes which gametes get passed on to which individuals.

Let's first get some data sets that we will be passing into `arrange_matings()`.
```{r trial-data}
tmp <- TT %>%
  filter(test_or_train == "test") %>%
  group_by(id, pop, group) %>%
  tally() %>%
  ungroup() %>%
  select(-n)

A <- tmp %>% filter(group == "wild")
B <- tmp %>% filter(group == "farmed")
```
Let's write it:
```r
`r paste(readLines("R/arrange_matings.R"), collapse = "\n")`
```

Now that we have that function, we can create a mating list for F1s like this:
```{r demo-arrange}
arrange_matings(A, B)
```

### Some data to play with

We need some scrambled founder data for the following functions for testing 
and demo.  So, here it is:
```{r make-demo-data}
Wf <- SFG %>%
  filter(group == "wild")
Ff <- SFG %>%
  filter(group == "farmed")
```
### make_f1s
And so, we can make a function to make F1's like this:
```r
`r paste(readLines("R/make_f1s.R"), collapse = "\n")`
```

Then we can use that to make a bunch of F1's and immediately segrate some haplotypes from them.
```{r demo_f1s}
newF1s <- make_f1s(Wf, Ff) %>%
  segregate_gametes()

newF1s[1:100,]
```

That is cool.  The harder part is the later generations, but not so bad,
it turns out.

### make_f2s

This function will take the same input as `make_f1s()` but then it will 
split the result into two data frames and make F2s from it.
```r
`r paste(readLines("R/make_f2s.R"), collapse = "\n")`
```

And we can use that thing like this:
```{r demo-f2}
newF2s <- make_f2s(Wf, Ff)
newF2s[1:100, ]
```

### make backcrosses

This is a single function that will make backcrosses to the first population (the A population).
If you want to make backcrosses in the other direction, you will just need to 
call it with the populations in a different order.  This is also going to be a wasteful function:
it is not going to work hard to make pures out of any extra individuals, etc.  It is going to make
as many backcrosses as it can, and no more. It is also not going to be population aware---that all
has to be done on the front end if you want to make sure that backcrosses are all within the same
population, for example.

Before we launch into this, let's talk about how many backcrosses you can make.  Imagine that you are
going to be backcrossing to the $A$ population which has $n_A$ test indivs.  And the other population
is the $B$ population which has $n_B$ individuals in it.  To figure out how many A-backcross 
indivs you can make without reusing any of your gene copies, you start by computing
$M = \min(\lfloor n_a/3 \rfloor, n_b)$.  Then the way you do this is

1. Hold out $2M$ of the $n_a$ individuals for backcrossing later
2. Make $2M$ F1s out of $M$ $A$'s and $M$ $B$'s
3. Mate the $2M$ $A$'s to the $2M$ F1's to get $4M$ backcrosses.

So, you can get $4M$ backcrosses out of it.

Let's write a function that does this:
```r
`r paste(readLines("R/make_bxs.R"), collapse = "\n")`
```

And we can use that like this:
```{r demo-bx}
newBXs <- make_bxs(Wf, Ff)
newBXs[1:100,]
```