---
title: "Putting it All Together"
output: 
  html_notebook:
    toc: true
---

```{r setup, include=FALSE}
# set the working directory always to the project directory (one level up)
knitr::opts_knit$set(root.dir = normalizePath(rprojroot::find_rstudio_root_file())) 
```


## Intro/Overview

This notebook documents the development of the strategy for putting together all the previous
functions so that I can start from a data set of individual genotypes and physical positions
and then I can do:

1. Choose train and test
1. Rank markers
1. Simulate data sets with different types of hybrids 
1. Write those data sets out in a directory structure that makes it easy to run newhybrids with Unix parallel.  



First we ensure that we load each of the functions:
```{r}
library(tidyverse)
library(stringr)
library(SalarHybPower)
```

We also want to have some example data.  We will just use the Nova Scotia data. But we will
call this dat:
```{r}
dat <- readRDS("intermediates/01/tidy-west.rds") %>%
  mutate(pop = str_sub(id, 1, 3),
         group = ifelse(pop == "AQU" | pop == "WLN", "farmed", "wild"))
```


## Split and Rank

We are going to have a single function that splits the same into training and test 
and also ranks the loci.  It will return a list with components `split_dat` and `ranked_markers`.

```r
`r paste(readLines("R/split_and_rank.R"), collapse = "\n")`
```
So, it works like this:
```{r}
SAR <- split_and_rank(dat)
```

## Simulate Data Sets

We will do this so that all the training individuals will end up with `z0s` or `z1s` in the data
set, and then we will make as many of the others as we can.  Since we are going to be just computing 
the scaled likelihoods for all these guys, it should be fine to just create everyone to be of one type
(i.e. Pure, F1, F2, Bx, etc.)  And I need to do something about whether I want to only have 
matings occur between individuals from the same population. (for F2s and BXs)

It looks like this:
```r
`r paste(readLines("R/create_hybrid_dataset.R"), collapse = "\n")`
```


See that that looks like:
```{r}
AllPops <- c("BDN", "CNR", "GRR", "LHR", "LPR")
create_hybrid_dataset(SAR, wild_pop = AllPops, hyb_cat = "F2", L = 5000, dir = "hyb_dir")
```

Then we can do:
```sh
 ~/Documents/git-repos/newhybrids/newhybs -d nh_data.txt -g P0 1 0 0 -g p1 0 0 1 -g F1 0 1 0 -g F2 .25 .5 .25 -g BX0 .5 .5 0 -g BX1 0 .5 .5 --pi-prior fixed  1 1 1 1 1 1
```

OK!  That is working pretty darn well.  NewHybrids converges very quickly.  I can easily get away with running it for 50 sweeps of 
burn in and 200 of data collection, which should go pretty darn fast, and I could do that over many data sets, each one from 
a different population.

And I can also lump all the populations together. In fact, that will be just fine for F1s, always.  

So, I only need to set up these simulations, write out all the data sets to directories with informative names,
and then rip through them with Unix parallel.  Then we need a function to read in the output into one massive tidy 
data frame for analysis.  