---
title: "Making Multiple Data Sets"
output: 
  html_notebook:
    toc: true
---

```{r setup, include=FALSE}
# set the working directory always to the project directory (one level up)
knitr::opts_knit$set(root.dir = normalizePath(rprojroot::find_rstudio_root_file())) 
```


## Intro/Overview

Just going to show how to create lots of data sets that can then be run through new hybrids.
We create our own nomenclature so that the directory name tells us about the simulation.

```{r}
library(tidyverse)
library(stringr)
library(SalarHybPower)
```

We also want to have some example data.  We will just use the Nova Scotia data. But we will
call this dat:
```{r}
dat <- readRDS("intermediates/01/tidy-west.rds") %>%
  mutate(pop = str_sub(id, 1, 3),
         group = ifelse(pop == "AQU" | pop == "WLN", "farmed", "wild"))
```

First, count how many individuals we have from each wild population:
```{r}
dat %>%
  group_by(pop) %>%
  summarize(num = n_distinct(id))
```

This means that if we are doing F2's for LHR we will only be able to make 4 or 5 per time,
and for backcrosses, we will only get about 4 per data set out of them.  OK.  Well, let us 
not worry about the number of individuals we get from each population.  Let's just do REPS reps...


Set up some info for the sims:
```{r}
SPLITS <- 3 # the number of times to split the data and rank markers
LOCS <- c(100, 250, 500, 1000)  # number of loci
POPLIST <- c("BDN", "CNR", "GRR", "LHR", "LPR")  # names of populations
HYB_CATS <- c("PureW", "PureF", "F1", "F2", "BX")
```

Then just cycle over things and do it
```{r}
main_out_dir <- "nh_reps_directory"
dir.create(main_out_dir)
set.seed(555)
for (s in 1:SPLITS) {
  SAR <- split_and_rank(dat)
  for (pop in POPLIST) {
    for (hc in HYB_CATS) {
      for (locs in LOCS) {
        dirname <- paste(s,pop,hc,locs, sep = "_")
        create_hybrid_dataset(SAR = SAR, wild_pop = pop, hyb_cat = hc, L = locs, 
                              dir = file.path(main_out_dir, dirname))
      }
    }
  }
  
}

```

That creates 300 directories, each with a single simulated data set in it.  Now I just need to run NewHybrids over each like this:
```sh
~/Documents/git-repos/newhybrids/newhybs -d nh_data.txt -g P0 1 0 0 -g p1 0 0 1 -g F1 0 1 0 -g F2 .25 .5 .25 -g BX0 .5 .5 0 -g BX1 0 .5 .5 --pi-prior fixed  1 1 1 1 1 1
```

Then slurp the output up and analyse it.

